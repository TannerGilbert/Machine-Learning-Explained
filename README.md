# Machine-Learning-Explained

This repository contains explanations and implementations of machine learning algorithms and concepts. The explanations are also available as articles on [my website](https://ml-explained.com/).

## Machine Learning Algorithms

* [Linear Regression](Algorithms/linear_regression)
* [Logistic Regression](Algorithms/logistic_regression)
* [K Nearest Neighbors](Algorithms/k_nearest_neighbors)
* [Decision Tree](Algorithms/decision_tree)
* [KMeans](Algorithms/kmeans)
* [Mean Shift](Algorithms/mean_shift)
* [DBSCAN](Algorithms/dbscan)
* [Random Forest](Algorithms/random_forest)
* [Adaboost](Algorithms/adaboost)
* [Gradient Boosting](Algorithms/gradient_boosting)
* [Principal Component Analysis (PCA)](Algorithms/principal_component_analysis)
* [Kernel PCA](Algorithms/kernel_pca)
* [Linear Discriminant Analysis (LDA)](Algorithms/linear_discriminant_analysis)

## Optimizers

* [Gradient Descent](Optimizers/gradient_descent)
* [Adagrad](Optimizers/adagrad)
* [Adadelta](Optimizers/adadelta)
* [RMSprop](Optimizers/rmsprop)
* [Adam](Optimizers/adam)
* [AdaMax](Optimizers/adamax)
* [Nadam](Optimizers/nadam)
* [AMSGrad](Optimizers/amsgrad)
* [AdamW](Optimizers/adamw)
* [QHM](Optimizers/qhm)
* [QHAdam](Optimizers/qhadam)
* [RAdam](Optimizers/radam)

## Activation Functions

* [ELU](Activation_Functions/README.md#exponential-linear-unit-elu)
* [GELU](Activation_Functions/README.md#gaussian-error-linear-unit-gelu)
* [Leaky RELU](Activation_Functions/README.md#leaky_relu)
* [Mish](Activation_Functions/README.md#mish)
* [RELU](Activation_Functions/README.md#rectified-linear-unit-relu)
* [SELU](Activation_Functions/README.md#scaled-exponential-linear-unit-selu)
* [Sigmoid](Activation_Functions/README.md#sigmoid-function)
* [SILU](Activation_Functions/README.md#sigmoid-weighted-linear-unit-silu--swish)
* [Softmax](Activation_Functions/README.md#softmax-function)
* [Softplus](Activation_Functions/README.md#softplus)
* [Tanh](Activation_Functions/README.md#tanh-function)

## Metrics

* [Binary Cross Entropy](Metrics/README.md#binary-cross-entropy)
* [Categorical Crossentropy](Metrics/README.md#categorical-crossentropy)
* [Accuracy Score](Metrics/README.md#accuracy-score)
* [Confusion Matrix](Metrics/README.md#confusion-matrix)
* [Precision](Metrics/README.md#precision)
* [Recall](Metrics/README.md#recall)
* [F1-Score](Metrics/README.md#f1-score)
* [Receiver operating characteristic (ROC)](Metrics/README.md#receiver-operating-characteristic-roc)
* [Area under the ROC curve (AUC)](Metrics/README.md#area-under-the-roc-curve-auc)
* [Hinge Loss](Metrics/README.md#hinge-loss)
* [KL Divergence](Metrics/README.md#kl-divergence)
* [Brier Score](Metrics/README.md#brier-score)
* [Mean Squared Error](Metrics/README.md#mean-squared-error)
* [Mean Squared Logaritmic Error](Metrics/README.md#mean-squared-logaritmic-error)
* [Mean Absolute Error](Metrics/README.md#mean-absolute-error)
* [Mean Absolute Percentage Error](Metrics/README.md#mean-absolute-percentage-error)
* [Median Absolute Error](Metrics/README.md#median-absolute-error)
* [Cosine Similartiy](Metrics/README.md#cosine-similarity)
* [R2 Score](Metrics/README.md#r2-score)
* [Tweedie Deviance](Metrics/README.md#tweedie-deviance)
* [D^2 Score](Metrics/README.md#d2-score)
* [Huber loss](Metrics/README.md#huber-loss)
* [Log Cosh Loss](Metrics/README.md#log-cosh-loss)


## Ensemble Methods

* [Averaging](Ensemble_Methods/code/averaging.py)
* [Bagging](Ensemble_Methods/code/bagging.py)
* [Blending](Ensemble_Methods/code/blending.py)
* [Majority Vote](Ensemble_Methods/code/majority_vote.py)
* [Stacking](Ensemble_Methods/code/stacking.py)
* [Stacking retrained](Ensemble_Methods/code/stacking_retrained.py)
* [Weighted Average](Ensemble_Methods/code/weighted_average.py)

## Contributing

Contributions to Machine-Learning-Explained are always welcome, whether code or documentation changes. For contribution guidelines, please see the [CONTRIBUTING.md file](CONTRIBUTING.md).

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE) file for details.